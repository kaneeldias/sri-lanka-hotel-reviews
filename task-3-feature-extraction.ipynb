{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T04:43:57.859250Z",
     "start_time": "2025-07-11T04:43:57.844536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim.downloader as api"
   ],
   "id": "4bd2e8a1448e3b3a",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 3 - Feature Extraction\n",
    "First we will load the ground truth reviews dataset."
   ],
   "id": "a7b48110a0e2f803"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T04:28:09.958835Z",
     "start_time": "2025-07-11T04:28:09.885306Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    review_id  location_id             hotel_name     city  \\\n",
       "0  1016464488     11953119  Nh Collection Colombo  Colombo   \n",
       "1  1016435128     11953119  Nh Collection Colombo  Colombo   \n",
       "2  1016307864     11953119  Nh Collection Colombo  Colombo   \n",
       "3  1016165618     11953119  Nh Collection Colombo  Colombo   \n",
       "4  1015472232     11953119  Nh Collection Colombo  Colombo   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  good stay found lighters toilet paper rolls no...       1   \n",
       "1  definitely recommend hotel excellent food good...       5   \n",
       "2  wonderful stay comfortable staycooperative sta...       5   \n",
       "3  favorite 4 star hotel colombo live new york ar...       5   \n",
       "4  excellent food stay excellent food especially ...       5   \n",
       "\n",
       "   ground_truth_sentiment  \n",
       "0                       1  \n",
       "1                       1  \n",
       "2                       1  \n",
       "3                       1  \n",
       "4                       1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>hotel_name</th>\n",
       "      <th>city</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>ground_truth_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1016464488</td>\n",
       "      <td>11953119</td>\n",
       "      <td>Nh Collection Colombo</td>\n",
       "      <td>Colombo</td>\n",
       "      <td>good stay found lighters toilet paper rolls no...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1016435128</td>\n",
       "      <td>11953119</td>\n",
       "      <td>Nh Collection Colombo</td>\n",
       "      <td>Colombo</td>\n",
       "      <td>definitely recommend hotel excellent food good...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1016307864</td>\n",
       "      <td>11953119</td>\n",
       "      <td>Nh Collection Colombo</td>\n",
       "      <td>Colombo</td>\n",
       "      <td>wonderful stay comfortable staycooperative sta...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016165618</td>\n",
       "      <td>11953119</td>\n",
       "      <td>Nh Collection Colombo</td>\n",
       "      <td>Colombo</td>\n",
       "      <td>favorite 4 star hotel colombo live new york ar...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1015472232</td>\n",
       "      <td>11953119</td>\n",
       "      <td>Nh Collection Colombo</td>\n",
       "      <td>Colombo</td>\n",
       "      <td>excellent food stay excellent food especially ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3,
   "source": [
    "reviews = pd.read_csv(\"ground_truth_reviews.csv\")\n",
    "reviews.head()"
   ],
   "id": "9604fa57454f8b96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.1. Bag of Words (BoW)\n",
    "Here, we will create a Bag of Words (BoW) representation of the reviews. \n",
    "This involves tokenizing the text and creating a matrix where each row corresponds to a review and each column corresponds to a word in the vocabulary."
   ],
   "id": "74ca8256b2f071d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T04:28:10.291156Z",
     "start_time": "2025-07-11T04:28:09.995341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(reviews[\"review\"])"
   ],
   "id": "d981539e1297b836",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T04:28:10.356973Z",
     "start_time": "2025-07-11T04:28:10.340276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "print(f\"Size of BoW vocabulary: {len(vocabulary)}\")"
   ],
   "id": "cda239dc36672a01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of BoW vocabulary: 17968\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see here that there are 17,968 unique words in the vocabulary extracted from the reviews.",
   "id": "6748508cabf84c91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T04:28:10.675002Z",
     "start_time": "2025-07-11T04:28:10.506079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bow_matrix = pd.DataFrame(X.toarray(), columns=vocabulary)\n",
    "print(f\"Shape of the BoW matrix: {bow_matrix.shape}\")"
   ],
   "id": "cb8d3e3f7755f730",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the BoW matrix: (5186, 17968)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The shape of the BoW matrix is (5186, 17968), meaning there are 5186 reviews, and each vector has 17968 features corresponding to the unique words in the vocabulary.",
   "id": "8697c7c1652aa171"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can even print the first row of the BoW matrix to see how it looks.",
   "id": "c9dd1b104be50a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:23:01.017106Z",
     "start_time": "2025-07-11T05:23:01.004447Z"
    }
   },
   "cell_type": "code",
   "source": "print(bow_matrix.iloc[0])",
   "id": "59bffc4dc5c67e26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000                   0\n",
      "01                    0\n",
      "0111and               0\n",
      "0120                  0\n",
      "0130                  0\n",
      "                     ..\n",
      "顶楼还有个游泳池不过没来得及享受一下    0\n",
      "𝐄𝐚𝐬𝐡𝐚𝐧𝐢               0\n",
      "𝐆𝐮𝐞𝐬𝐭                 0\n",
      "𝐑𝐞𝐥𝐚𝐭𝐢𝐨𝐧𝐬             0\n",
      "𝐢𝐧                    0\n",
      "Name: 0, Length: 17968, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's check for some words from the first review that are present.",
   "id": "3044901345d1832e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:25:00.399464Z",
     "start_time": "2025-07-11T05:25:00.387157Z"
    }
   },
   "cell_type": "code",
   "source": "print(bow_matrix.iloc[0][bow_matrix.iloc[0] > 0])",
   "id": "c2479c7ad0141a42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beds        1\n",
      "booked      1\n",
      "even        1\n",
      "found       1\n",
      "give        1\n",
      "good        1\n",
      "lighters    1\n",
      "non         1\n",
      "paper       1\n",
      "rolls       1\n",
      "room        1\n",
      "smoking     1\n",
      "stay        1\n",
      "though      1\n",
      "toilet      1\n",
      "twin        1\n",
      "us          1\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.2. Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "Here, we will create a Term Frequency-Inverse Document Frequency (TF-IDF) representation of the reviews."
   ],
   "id": "314b81df3242e86b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T04:28:11.094091Z",
     "start_time": "2025-07-11T04:28:10.812319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(reviews['review'])"
   ],
   "id": "cf90239ebfc9f9ff",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T04:28:11.161419Z",
     "start_time": "2025-07-11T04:28:11.144323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print(f\"Size of TF-IDF vocabulary: {len(feature_names)}\")"
   ],
   "id": "caa5a0ea4ac612f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TF-IDF vocabulary: 17968\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Once again, we can see that there are 17,968 unique words in the vocabulary extracted from the reviews.",
   "id": "a612163a994ff2f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T04:28:11.368363Z",
     "start_time": "2025-07-11T04:28:11.189700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tfidf_matrix_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "print(f\"Shape of the TF-IDF matrix: {tfidf_matrix_df.shape}\")"
   ],
   "id": "4e46a089033e6374",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the TF-IDF matrix: (5186, 17968)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The shape of the TF-IDF matrix is also (5186, 17968), meaning there are 5186 reviews, and each vector has 17968 features corresponding to the unique words in the vocabulary.",
   "id": "b0e1b979eacb9615"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Once again, we can print the first row of the TF-IDF matrix to see how it looks.",
   "id": "67ded8e06d98e913"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:23:54.938467Z",
     "start_time": "2025-07-11T05:23:54.928499Z"
    }
   },
   "cell_type": "code",
   "source": "print(tfidf_matrix_df.iloc[0])",
   "id": "a39c6baec1392411",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000                   0.0\n",
      "01                    0.0\n",
      "0111and               0.0\n",
      "0120                  0.0\n",
      "0130                  0.0\n",
      "                     ... \n",
      "顶楼还有个游泳池不过没来得及享受一下    0.0\n",
      "𝐄𝐚𝐬𝐡𝐚𝐧𝐢               0.0\n",
      "𝐆𝐮𝐞𝐬𝐭                 0.0\n",
      "𝐑𝐞𝐥𝐚𝐭𝐢𝐨𝐧𝐬             0.0\n",
      "𝐢𝐧                    0.0\n",
      "Name: 0, Length: 17968, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's check for some words from the first review that are present in the TF-IDF matrix.",
   "id": "a0eb900c4b61a35c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:25:15.819941Z",
     "start_time": "2025-07-11T05:25:15.810681Z"
    }
   },
   "cell_type": "code",
   "source": "print(tfidf_matrix_df.iloc[0][tfidf_matrix_df.iloc[0] > 0])",
   "id": "7334668064fb7729",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beds        0.203157\n",
      "booked      0.181399\n",
      "even        0.144703\n",
      "found       0.203431\n",
      "give        0.205972\n",
      "good        0.092402\n",
      "lighters    0.406354\n",
      "non         0.280659\n",
      "paper       0.296387\n",
      "rolls       0.342779\n",
      "room        0.095741\n",
      "smoking     0.374567\n",
      "stay        0.084388\n",
      "though      0.192924\n",
      "toilet      0.232811\n",
      "twin        0.320513\n",
      "us          0.112083\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can also check for the top 10 words with the highest TF-IDF scores in the first review.",
   "id": "ea2cb48f8e68d6a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:25:43.207825Z",
     "start_time": "2025-07-11T05:25:43.194455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "top_tfidf_words = tfidf_matrix_df.iloc[0].nlargest(10)\n",
    "print(\"Top 10 words with highest TF-IDF scores in the first review:\")\n",
    "print(top_tfidf_words)"
   ],
   "id": "92b5f502bb8e9042",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words with highest TF-IDF scores in the first review:\n",
      "lighters    0.406354\n",
      "smoking     0.374567\n",
      "rolls       0.342779\n",
      "twin        0.320513\n",
      "paper       0.296387\n",
      "non         0.280659\n",
      "toilet      0.232811\n",
      "give        0.205972\n",
      "found       0.203431\n",
      "beds        0.203157\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.3. Word2Vec\n",
    "Here, we will create a Word2Vec model using the reviews."
   ],
   "id": "62c59a1fb9dcdf73"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First, we need to tokenize the reviews into words.",
   "id": "8c3b31395a655245"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T04:28:12.897051Z",
     "start_time": "2025-07-11T04:28:11.435375Z"
    }
   },
   "cell_type": "code",
   "source": "tokenized_reviews = [word_tokenize(review.lower()) for review in reviews['review']]",
   "id": "7c718332d467c8de",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we can train a Word2Vec model on the tokenized reviews. We will use a vector size of 500, a window size of 100, and set the minimum count to 0 to include all words.",
   "id": "5c57a94b31060822"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T04:49:48.427003Z",
     "start_time": "2025-07-11T04:48:53.752885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "w2v_model = Word2Vec(sentences=tokenized_reviews, vector_size=500, window=100, min_count=0, workers=8, sg=1)\n",
    "w2v_model.save(\"word2vec.model\")"
   ],
   "id": "e979a82fef0602ae",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T04:54:19.027351Z",
     "start_time": "2025-07-11T04:54:19.019402Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Shape of the Word2Vec matrix: {w2v_model.wv.vectors.shape}\")",
   "id": "2c0dbf4fa6760696",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Word2Vec matrix: (17998, 500)\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see that the Word2Vec model has a shape of (17998, 500), meaning there are 17,998 unique words in the vocabulary, and each word is represented by a 500-dimensional vector.",
   "id": "f9e537f84cc26452"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can also check the vector value for a specific word, such as \"bed\".",
   "id": "980133044208f965"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T04:48:31.994722Z",
     "start_time": "2025-07-11T04:48:31.982104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bed_vector = w2v_model.wv['bed']\n",
    "print(f\"Vector for 'bed': {bed_vector}\")"
   ],
   "id": "5ab246d54b64de17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'bed': [ 0.01328971  0.07161278  0.06789137 -0.04979965 -0.2273252  -0.22884874\n",
      "  0.23627952  0.35391557  0.08354398 -0.06751227 -0.553474   -0.08800868\n",
      "  0.04060964 -0.10346626 -0.16143037  0.0650394   0.17125958 -0.22617334\n",
      "  0.07321496 -0.2670425   0.45155233  0.08253594  0.00937192 -0.04241944\n",
      " -0.3494298  -0.15199725 -0.32324192 -0.11509268  0.26708007 -0.1962376\n",
      "  0.5659793  -0.05382812  0.48235992 -0.10746121 -0.31623477 -0.00499177\n",
      "  0.03613308  0.11710807  0.07628288 -0.35120985  0.55010337 -0.3976128\n",
      "  0.06993041 -0.3392599   0.23556261  0.24872307 -0.01639684  0.2988197\n",
      "  0.1873349   0.37989455  0.26626685  0.07608344  0.10935228 -0.03928052\n",
      " -0.2505354   0.27249217 -0.17389402  0.19608381 -0.16193092 -0.11035869\n",
      " -0.11730596  0.02260891  0.09064058 -0.36476663 -0.11571939  0.3008439\n",
      "  0.12167478  0.00809896 -0.14899743  0.1450408  -0.05531208  0.06742488\n",
      "  0.05966388 -0.08510252  0.17568527 -0.44088602  0.06441578  0.09202424\n",
      " -0.08971269  0.0678653  -0.41538003  0.10379695 -0.5067962   0.2839775\n",
      "  0.23520176 -0.57104254  0.04925273  0.18557464 -0.09381876 -0.22323202\n",
      "  0.46552718  0.07121982 -0.01904635  0.18692793 -0.05782707  0.27683285\n",
      "  0.00816723 -0.7131493   0.00627891  0.25098878]\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can also find the most similar words to \"bed\" using the Word2Vec model.",
   "id": "993ab7ce1cc44b02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T04:48:33.952990Z",
     "start_time": "2025-07-11T04:48:33.940657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "similar_words = w2v_model.wv.most_similar('bed')\n",
    "print(f\"Most similar words to 'bed': {similar_words}\")"
   ],
   "id": "66b72ff2d3f9081b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'bed': [('bathroom', 0.7106977701187134), ('deet', 0.6923396587371826), ('drenching', 0.6879812479019165), ('hacking', 0.6844325661659241), ('barren', 0.6829866766929626), ('ragged', 0.6811744570732117), ('partially', 0.679260790348053), ('squeezed', 0.6706869602203369), ('classed', 0.6693724393844604), ('hte', 0.6689077019691467)]\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can also perform analogy tasks using the Word2Vec model. For example, we can find a word that is to \"colombo\" as \"galle\" is to \"city\".",
   "id": "3e66f13a3a5a5c18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T04:48:38.339283Z",
     "start_time": "2025-07-11T04:48:38.328913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "analogy_result = w2v_model.wv.most_similar(positive=['colombo', 'galle'], negative=['city'], topn=1)\n",
    "print(f\"Analogy result for 'colombo' - 'city' + 'galle': {analogy_result}\")"
   ],
   "id": "ab980ade5666e480",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy result for 'colombo' - 'city' + 'galle': [('fort', 0.5598229765892029)]\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here, we can see that the model determines that Colombo - City + Galle = Fort. Which makes intuitive sense. ",
   "id": "469b0302183c6a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can also perform other analogy tasks, such as finding a word that is to \"bed\" as \"internet\" is to \"sleep\".",
   "id": "e95af2278441f3d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:28:17.264548Z",
     "start_time": "2025-07-11T05:28:17.238812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "analogy_result = w2v_model.wv.most_similar(positive=['bed', 'internet'], negative=['sleep'], topn=1)\n",
    "print(f\"Analogy result for 'bed' - 'sleep' + 'internet': {analogy_result}\")"
   ],
   "id": "28d8eb944669afc6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy result for 'bed' - 'sleep' + 'internet': [('connection', 0.5347010493278503)]\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here, it determined that Bed - Sleep + Internet = Connection. Which also makes sense.",
   "id": "13ce78ecbd2b934b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's check another analogy task, such as finding a word that is to \"bed\" as \"water\" is to \"pillow\".",
   "id": "7cf118a9f9407852"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T04:48:44.057903Z",
     "start_time": "2025-07-11T04:48:44.049415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "analogy_result = w2v_model.wv.most_similar(positive=['bed', 'water'], negative=['pillow'], topn=1)\n",
    "print(f\"Analogy result for 'bed' - 'pillow' + 'water': {analogy_result}\")"
   ],
   "id": "d3fd17333d4d6398",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy result for 'bed' - 'pillow' + 'water': [('hot', 0.5803027153015137)]\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here, it determined that Bed - Pillow + Water = Hot. This is unexpected, and highlights the limitations of the model in understanding certain relationships.",
   "id": "157710c63bdb227c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can also check for some common relationships, but those which might not be present in the dataset.",
   "id": "8aceb38f44fb1a48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:06:21.928728Z",
     "start_time": "2025-07-11T05:06:21.899066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = w2v_model.wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n",
    "print(f\"Analogy result for 'king' - 'man' + 'woman': {result}\")"
   ],
   "id": "9dfcd5cc9ba0fddc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy result for 'king' - 'man' + 'woman': [('tomato', 0.6332396864891052)]\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here, we see that the model struggles to come up with a meaningful analogy for this relationship, which highlights the limitations of the dataset to generalize.",
   "id": "b314056fa78db642"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, we can vectorize the reviews using the Word2Vec model by averaging the word vectors for each review.",
   "id": "2b2f2872498ed619"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T04:56:31.994715Z",
     "start_time": "2025-07-11T04:56:29.862556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_review_vector(review, model):\n",
    "    tokens = word_tokenize(review.lower())\n",
    "    vector = sum(model.wv[token] for token in tokens if token in model.wv) / len(tokens)\n",
    "    return vector\n",
    "\n",
    "w2v_review_vectors = reviews['review'].apply(lambda x: get_review_vector(x, w2v_model))"
   ],
   "id": "f7e4b121d99a1a8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the review vectors: (5186,)\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T04:57:58.447171Z",
     "start_time": "2025-07-11T04:57:58.440170Z"
    }
   },
   "cell_type": "code",
   "source": "print(w2v_review_vectors[0].shape)",
   "id": "63944887fd1f648d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see that the dataset now consists of 5186 reviews, and each review is represented by a 500-dimensional vector. We can even print the first review vector to see how it looks.",
   "id": "2e966ea9dd62f86f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T04:58:00.481937Z",
     "start_time": "2025-07-11T04:58:00.473444Z"
    }
   },
   "cell_type": "code",
   "source": "print(w2v_review_vectors[0])",
   "id": "e941969a260db86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05941431  0.05278328  0.05683436  0.06084106  0.00153431 -0.06041967\n",
      "  0.02414834  0.14309305  0.09195112 -0.02776968 -0.0718798   0.0629831\n",
      "  0.04242303  0.04373344  0.02424304 -0.11129151  0.09293571  0.01068859\n",
      " -0.02303246  0.04634799 -0.01803079 -0.11564458  0.07989132 -0.1711425\n",
      "  0.13802753  0.02999704  0.07014416  0.03651328 -0.12704466  0.02242588\n",
      "  0.06168661  0.05890016 -0.04253672  0.01672608  0.08675099  0.020031\n",
      "  0.05894509 -0.04779759 -0.01879394 -0.07501208 -0.06401239 -0.03748969\n",
      " -0.06575883  0.18574882 -0.05097859 -0.02662526 -0.07610609  0.05809728\n",
      " -0.00529236  0.01340407 -0.08323544  0.03447828 -0.03297705 -0.11842287\n",
      "  0.00905023 -0.0862248   0.08153416  0.06703254 -0.06113864 -0.13685906\n",
      "  0.05145503  0.01248156 -0.07273591  0.00935992 -0.05749336  0.04678034\n",
      "  0.00579022 -0.03716632  0.07696224  0.06709893 -0.05255026 -0.07095324\n",
      "  0.04185233 -0.02927235  0.04573394  0.01839506 -0.02468534 -0.00773567\n",
      "  0.1293459  -0.02236648  0.02766605  0.02034421 -0.0520097   0.13733438\n",
      " -0.04098789  0.0013913  -0.03975083 -0.00826373 -0.00054084  0.01393336\n",
      " -0.00595887 -0.03120405  0.00609463 -0.05527792  0.00530134  0.0785369\n",
      "  0.00043039 -0.00217965  0.05040971  0.05661635 -0.0361982   0.08899555\n",
      " -0.05054795  0.084952    0.04274637  0.01972341 -0.00817795  0.04881581\n",
      "  0.06556583  0.06451881 -0.01658507 -0.1405452  -0.03013869  0.01760501\n",
      " -0.01941133 -0.02862087  0.07473141 -0.04311135  0.03979102 -0.11502556\n",
      "  0.05955265 -0.00445326 -0.00620346 -0.04081677  0.00433991 -0.02937696\n",
      " -0.07678735 -0.0032433   0.00811523  0.01785665 -0.03439836  0.00139636\n",
      " -0.01958577  0.01027237  0.0071087   0.02831025 -0.04653187 -0.03142883\n",
      "  0.00504755 -0.05459191  0.03747455 -0.09268723 -0.01810614  0.01099901\n",
      "  0.05671565  0.05603942  0.0203227   0.02927796  0.03420451  0.01341498\n",
      "  0.03871607  0.02472224  0.05491487  0.0794434  -0.08191463  0.01053456\n",
      "  0.03776918  0.07330733 -0.04963019  0.02775228  0.03322259 -0.01205553\n",
      " -0.01362997  0.01082148 -0.01306519 -0.00331534  0.01298389  0.0274467\n",
      "  0.02408282  0.09160655  0.10045502  0.04325597  0.02713613  0.03652669\n",
      "  0.03881894  0.01666495 -0.05406153  0.0371437  -0.09406953 -0.03068928\n",
      " -0.07764098 -0.03842721 -0.00966097  0.07425486 -0.05995856 -0.03259978\n",
      "  0.06418981  0.02279795  0.07656746  0.04085734  0.08619927 -0.0135688\n",
      "  0.02971894  0.11668026 -0.01541632  0.1081453   0.02066655 -0.04460292\n",
      "  0.02502942  0.00139651 -0.00467132  0.0929966   0.0486584  -0.02143715\n",
      "  0.11950623 -0.01481481 -0.03505747  0.06646963 -0.05107103  0.01855905\n",
      "  0.04114626 -0.07464121 -0.00870073 -0.00557311 -0.02762168 -0.11221654\n",
      " -0.12734543 -0.00426555 -0.03159483  0.136895    0.08674254  0.07275951\n",
      "  0.05582315 -0.02535766 -0.03271172 -0.01196913  0.11322891 -0.08389136\n",
      "  0.03825784 -0.07273757  0.00928872 -0.11328082 -0.03441842  0.08159819\n",
      " -0.08950713 -0.07021742 -0.12601133 -0.07005793  0.05156516 -0.01963805\n",
      " -0.02807821 -0.01707822 -0.05277732  0.15668128 -0.09465822  0.11167973\n",
      "  0.00418153 -0.0712979  -0.01970329  0.04678633  0.04553313 -0.11997477\n",
      " -0.0083086  -0.0055734  -0.08135603  0.10519568  0.11249581  0.05973782\n",
      " -0.0408756   0.09367139  0.0561452   0.00232975 -0.01383792 -0.10909694\n",
      " -0.01757128  0.09244303 -0.11888868  0.14351681 -0.04736725 -0.12304479\n",
      " -0.03541771  0.06177517 -0.0627442  -0.01914451 -0.0318083  -0.05701599\n",
      "  0.08631394 -0.11747115 -0.04492816  0.02983932  0.05913571  0.0815476\n",
      " -0.08625191 -0.07965189  0.17766128 -0.16349238  0.03930005 -0.06759623\n",
      "  0.0857489   0.06444143 -0.11192571  0.10157084 -0.07444755  0.15291415\n",
      "  0.03355011  0.0451332   0.1182341  -0.11312983  0.02568753  0.00468151\n",
      "  0.00758211  0.00951216 -0.0414604   0.06706429  0.02902234 -0.12670587\n",
      " -0.09371304  0.06578811 -0.03925865 -0.05449225 -0.08674606 -0.16486225\n",
      "  0.01970502  0.06619784 -0.08160373 -0.05749887 -0.08748095 -0.05560225\n",
      "  0.05729439 -0.02856831  0.07288709 -0.0920781  -0.06947271  0.03423519\n",
      " -0.071564   -0.01998242 -0.00871458  0.08215103 -0.08429029 -0.02312909\n",
      "  0.04431868  0.03581883  0.00823012  0.00814686  0.0160511  -0.06925596\n",
      " -0.02871381  0.055398   -0.01138051 -0.04167892  0.01202317 -0.071787\n",
      " -0.01939452  0.05113922  0.03818443 -0.05007578 -0.18112095  0.0984839\n",
      " -0.02246826 -0.00932714  0.05490765 -0.08579672 -0.07298899  0.00250798\n",
      " -0.00098041  0.0858667  -0.02238467  0.02068366 -0.05267332  0.00860894\n",
      "  0.0166413   0.03630411 -0.05658137 -0.01765957 -0.09900284  0.00293555\n",
      "  0.05410141 -0.007735   -0.11104105  0.00039962  0.01459292 -0.13323525\n",
      " -0.09484798 -0.02634156  0.0424615   0.04152742 -0.08388422  0.01843857\n",
      "  0.05721395 -0.10965751  0.07587644 -0.02651529  0.02365856 -0.01252323\n",
      "  0.00977479 -0.13558333 -0.0042355   0.05668472 -0.00706868 -0.02078401\n",
      " -0.0172279   0.18462034  0.02244576 -0.10979936  0.138474    0.05398798\n",
      " -0.01557931  0.01596964 -0.07387263 -0.00660581 -0.01918735  0.0024186\n",
      " -0.0280062  -0.03942594 -0.0865502  -0.09758934  0.08352688  0.19100893\n",
      "  0.09174597 -0.0107978  -0.00886397 -0.05421773 -0.13258292 -0.14327432\n",
      "  0.09079048 -0.00654228  0.04468709  0.06263255  0.11373334 -0.07720396\n",
      " -0.08160643  0.01284705 -0.04889076  0.03987947 -0.1599114   0.02146346\n",
      "  0.06984997  0.02989492  0.0082177  -0.00995885 -0.11053488  0.01120382\n",
      "  0.0201248  -0.0575217  -0.02653528 -0.04262697 -0.08113553  0.01142486\n",
      " -0.07294176  0.01260298  0.03101893 -0.09057096  0.07433301 -0.00600138\n",
      "  0.15951839  0.02881564 -0.0097457  -0.04650138  0.03731982 -0.01207166\n",
      " -0.04950698 -0.04056637 -0.10596608 -0.12554473  0.00782137 -0.10743771\n",
      " -0.05233064 -0.03822479  0.07644517 -0.05269986 -0.1425724   0.12480315\n",
      " -0.03046442 -0.03105876 -0.05244651 -0.14864719 -0.01773807 -0.15525807\n",
      "  0.04996511  0.2219704  -0.03726721  0.03865752 -0.06154536 -0.21630055\n",
      " -0.02311496  0.09251285  0.01438145 -0.06266319 -0.29808727 -0.04396446\n",
      "  0.10804594 -0.11540791 -0.13809712  0.14444292  0.14984895  0.01664639\n",
      " -0.07919922  0.21298975  0.05839964  0.06730689 -0.02437264  0.06216601\n",
      "  0.01731545 -0.00355161  0.04213471  0.1095086  -0.04402519  0.00528907\n",
      " -0.05123578  0.13368787]\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.4. GloVe",
   "id": "c49eb42ce3181f85"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here, we will use the GloVe model to create word embeddings for the reviews.",
   "id": "d6ed4d773bc5b2dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:02:55.901640Z",
     "start_time": "2025-07-11T05:02:09.202363Z"
    }
   },
   "cell_type": "code",
   "source": "glove_model = api.load('glove-wiki-gigaword-100')",
   "id": "c365c85bf368dca4",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:02:55.917735Z",
     "start_time": "2025-07-11T05:02:55.911127Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Shape of the GloVe model: {glove_model.vectors.shape}\")",
   "id": "72ba43c23b425163",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the GloVe model: (400000, 100)\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see that the GloVe model has a shape of (400000, 100), meaning there are 400,000 unique words in the vocabulary, and each word is represented by a 100-dimensional vector.",
   "id": "428214d44e3a56e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can check the vector value for a specific word, such as \"bed\".",
   "id": "b2e58fb6e9344e39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:03:25.082512Z",
     "start_time": "2025-07-11T05:03:25.074566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bed_vector_glove = glove_model['bed']\n",
    "print(f\"Vector for 'bed' in GloVe: {bed_vector_glove}\")"
   ],
   "id": "854875cb035c9056",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'bed' in GloVe: [-0.83528    0.57023    0.19219   -0.025946  -0.50039    0.36531\n",
      "  0.16811    0.98349   -0.16987   -0.40123    0.82593    0.77665\n",
      "  0.30743    1.1451     1.0567    -0.46868   -0.48286   -0.26397\n",
      " -0.14814   -0.82403   -0.31156    0.56133   -0.12384   -0.054355\n",
      "  0.42796    0.38446   -0.38117   -0.53408   -0.34122    0.15891\n",
      "  0.30952   -0.16873    0.36541    0.035137  -0.0095616  0.79946\n",
      " -0.50871   -0.031998   0.95187   -0.56081    0.23932    0.014487\n",
      " -0.15236   -0.73492   -0.24992    0.36617   -1.2171     0.42764\n",
      "  0.47683   -0.28761   -0.46801   -0.44108    0.641      1.0611\n",
      " -0.14081   -1.885     -0.20596   -0.087876   1.2402     0.13708\n",
      "  0.40899    0.5898    -0.14214   -0.13007    0.31583    0.60933\n",
      "  1.0137    -0.31204   -0.34454   -0.45771   -0.26633    0.067238\n",
      "  0.6028    -0.21555    0.27647    0.51912    0.33038   -0.1537\n",
      "  0.36153    0.14506    0.021452   0.71533    0.33153    0.32344\n",
      " -0.41465   -0.45996    0.2721    -0.37398   -0.8419     0.42759\n",
      "  0.44187   -0.68238    0.81183   -0.16322   -0.060373   0.1544\n",
      "  0.025293  -0.25826    1.1413    -0.20566  ]\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can also find the most similar words to \"bed\" using the GloVe model.",
   "id": "c46f4e46c953c31d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:03:27.161483Z",
     "start_time": "2025-07-11T05:03:27.047825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "similar_words_glove = glove_model.most_similar('bed', topn=5)\n",
    "print(f\"Most similar words to 'bed' in GloVe: {similar_words_glove}\")"
   ],
   "id": "3215fcb551809274",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'bed' in GloVe: [('beds', 0.7630817890167236), ('sleeping', 0.7616754770278931), ('room', 0.7250887155532837), ('bedroom', 0.6915374994277954), ('mattress', 0.6799734830856323)]\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Similar to before, we can perform analogy tasks using the GloVe model. For example, we can find a word that is to \"colombo\" as \"galle\" is to \"city\".",
   "id": "6efc6e808b1d65ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:03:43.164348Z",
     "start_time": "2025-07-11T05:03:43.140571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = glove_model.most_similar(positive=['colombo', 'galle'], negative=['city'], topn=1)\n",
    "print(f\"Analogy result for 'colombo' - 'city' + 'galle' in GloVe: {result}\")"
   ],
   "id": "fb90ce337d2f7c0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy result for 'colombo' - 'city' + 'galle' in GloVe: [('kandy', 0.5980703830718994)]\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here, we see that the model determines that Colombo - City + Galle = Kandy, which doesn't make much sense, but highlights the limitations of the model in specializing to specific domains.",
   "id": "4b8c02249635134e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:04:00.334935Z",
     "start_time": "2025-07-11T05:04:00.303154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = glove_model.most_similar(positive=['bed', 'internet'], negative=['sleep'], topn=1)\n",
    "print(f\"Analogy result for 'bed' - 'sleep' + 'internet' in GloVe: {result}\")"
   ],
   "id": "698c26d7d05f03de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy result for 'bed' - 'sleep' + 'internet' in GloVe: [('web', 0.7473989725112915)]\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "However for more generic relationships, the model performs better. For example, it determines that Bed - Sleep + Internet = Web, which makes sense.",
   "id": "c504ac619903c5e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:05:16.739278Z",
     "start_time": "2025-07-11T05:05:16.713569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = glove_model.most_similar(positive=['bed', 'water'], negative=['pillow'], topn=1)\n",
    "print(f\"Analogy result for 'bed' - 'pillow' + 'water' in GloVe: {result}\")"
   ],
   "id": "323a41ad00474ba2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy result for 'bed' - 'pillow' + 'water' in GloVe: [('electricity', 0.651475727558136)]\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here it determined that Bed - Pillow + Water = Electricity, which is similar to the Word2Vec model, but again highlights the limitations of the model in understanding certain relationships.",
   "id": "d663a5a323b4780c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:06:52.131207Z",
     "start_time": "2025-07-11T05:06:52.107751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = glove_model.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n",
    "print(f\"Analogy result for 'king' - 'man' + 'woman' in GloVe: {result}\")"
   ],
   "id": "e68b0ec0836877a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy result for 'king' - 'man' + 'woman' in GloVe: [('queen', 0.7698540091514587)]\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "However, this model does perform very well on generic relationships, such as the one above.",
   "id": "7eabdac697225884"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, we can vectorize the reviews using the GloVe model by averaging the word vectors for each review.",
   "id": "533b4e0b6063047d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:07:38.105644Z",
     "start_time": "2025-07-11T05:07:36.010985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_glove_review_vector(review, model):\n",
    "    tokens = word_tokenize(review.lower())\n",
    "    vector = sum(model[token] for token in tokens if token in model) / len(tokens)\n",
    "    return vector\n",
    "\n",
    "glove_review_vectors = reviews['review'].apply(lambda x: get_glove_review_vector(x, glove_model))"
   ],
   "id": "b3b512bc7e504290",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:07:38.843436Z",
     "start_time": "2025-07-11T05:07:38.837813Z"
    }
   },
   "cell_type": "code",
   "source": "print(glove_review_vectors[0].shape)",
   "id": "fa65cd00cf714804",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:07:43.139223Z",
     "start_time": "2025-07-11T05:07:43.133515Z"
    }
   },
   "cell_type": "code",
   "source": "print(glove_review_vectors[0])",
   "id": "d3bc900c5359fd1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.88056052e-01  3.77647102e-01  1.80472806e-01 -2.49550462e-01\n",
      " -1.42016843e-01  2.01147333e-01  2.88872309e-02  3.18506420e-01\n",
      "  1.19629153e-03 -4.60127629e-02  1.55070558e-01 -2.23748293e-02\n",
      "  1.50911957e-01  3.93529832e-01  1.43757939e-01 -2.64934957e-01\n",
      "  5.18198982e-02  7.59257153e-02 -8.40708688e-02  1.82777029e-02\n",
      "  2.48962566e-01  1.36617050e-01 -3.27359401e-02 -7.88827762e-02\n",
      "  1.87790766e-01 -1.64021358e-01 -7.92405903e-02 -5.14445305e-01\n",
      " -1.69924602e-01 -8.06976482e-02  1.77850589e-01  1.78253531e-01\n",
      " -4.94481176e-02  4.44965810e-02  9.72842351e-02  4.50662911e-01\n",
      " -6.32083565e-02  5.56944720e-02 -3.69871669e-02 -1.35416597e-01\n",
      " -2.10813001e-01 -3.27006012e-01  2.99377125e-02 -3.23578984e-01\n",
      "  8.58942345e-02 -3.25722359e-02 -1.28372878e-01 -4.04816456e-02\n",
      " -1.16261974e-01 -6.93872929e-01  1.02837920e-01 -1.24429323e-01\n",
      "  1.55044673e-02  7.55103111e-01 -8.50968882e-02 -1.64652193e+00\n",
      "  4.19850573e-02 -4.18368131e-02  1.29623473e+00  1.81528121e-01\n",
      "  5.41634560e-02  4.76835877e-01 -5.44381477e-02  1.27155021e-01\n",
      "  2.54989564e-01  1.51871875e-01  4.92383391e-01  1.83410361e-01\n",
      " -1.70542151e-02 -3.74497175e-01  3.16545963e-02 -2.04930469e-01\n",
      "  1.64369717e-01 -1.11441709e-01  3.55701149e-02  2.96174854e-01\n",
      "  1.08367763e-01 -1.47139579e-01 -4.23867017e-01  6.69590607e-02\n",
      "  4.77917850e-01 -3.22319418e-02 -1.80994079e-01  1.81923777e-01\n",
      " -1.10856342e+00 -3.75966638e-01  2.21374109e-01 -6.24504499e-02\n",
      " -2.18045592e-01 -1.82454102e-02  3.35293189e-02 -1.74025834e-01\n",
      "  2.73561686e-01 -2.15649948e-01 -3.87719393e-01  2.32562944e-02\n",
      " -1.30344585e-01 -3.68398204e-02  5.99484205e-01 -3.24104093e-02]\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:07:48.122719Z",
     "start_time": "2025-07-11T05:07:48.115913Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Shape of the GloVe review vectors: {glove_review_vectors.shape}\")",
   "id": "2f0976dbc0bece7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the GloVe review vectors: (5186,)\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here, we can see that the dataset now consists of 5186 reviews, and each review is represented by a 100-dimensional vector. We can even print the first review vector to see how it looks.",
   "id": "521c8b21b23cebb8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, we can save all the feature matrices to CSV files for further use.",
   "id": "6199165f90522f88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:15:09.365498Z",
     "start_time": "2025-07-11T05:15:09.359766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_matrices = {\n",
    "    'bow': bow_matrix,\n",
    "    'tfidf': tfidf_matrix_df,\n",
    "    'word2vec': w2v_review_vectors,\n",
    "    'glove': glove_review_vectors\n",
    "}"
   ],
   "id": "ab0ebccd6cc438e9",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T05:18:10.899610Z",
     "start_time": "2025-07-11T05:16:02.900202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, matrix in feature_matrices.items():\n",
    "    print(f\"Saving {name} feature matrix.\")\n",
    "    matrix.to_csv(f\"feature_matrix_{name}.csv\", index=False)"
   ],
   "id": "59e6f466cba38285",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving bow feature matrix.\n",
      "Saving tfidf feature matrix.\n",
      "Saving word2vec feature matrix.\n",
      "Saving glove feature matrix.\n"
     ]
    }
   ],
   "execution_count": 107
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
